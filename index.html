<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>reveal.js</title>

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/white.css">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css">
	</head>
	<body>
		<div class="reveal">
		  <div class="slides">




<!-- =========================================================================================================================  -->

			  <section>

			    <h1> Paper Presentation </h1>
<a href="https://journals.sagepub.com/doi/10.1177/17456916231201401?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub%20%200pubmed">"Transmission Versus Truth, Imitation Versus Innovation: What Children Can Do That Large Language and Language-and-Vision Models Cannot (Yet)" (Yiu, Kosoy, and Gopnik 2023)</a>

			   <br>
Peter Romero, 15.12.2023
			  </section>


<!-- =========================================================================================================================  -->
			  
			  <section>

			  <section>
			    <h2> Central Question </h1>
			    Individual agency of AI
			   <br>
			    vs. new cultural technology

			  </section>

<!-- --------------------------------------------------------------- -->
			  
			  <section>

			    <h2> Cultural Technologies: </h2>

<ul>
  <li>Language itself</li>
  <li>Writing</li>
  <li>Print</li>
  <li>Libraries</li>
  <li>Internet</li>
  <li>LLM ?</li>
</ul>

			  </section>


<!-- --------------------------------------------------------------- -->
	
			  <section>

			    <h2> Reason: Epistemic Processes </h2>

			    Epistemic Process = truth seeking

			    <br>
Agents actively solve the <b>"inverse problem"</b> 
			    <br>
(= internally reconstructing the structure of a changing, always novel environment)
			    <br>
Mostly human-like systems do that; 
			    <br>
foremost reinforcement learning; 
			    <br>
			    particularly model-based systems
			  </section>


<!-- --------------------------------------------------------------- -->
	
			  <section>

			    <h2> Reason: Epistemic Processes </h2>
On the other hand, LLM and Vision rather rely on statistical inferences from existing, vast amounts of data

			    <br>
			    Hence, LLM/Vision are tools of faithful cultural transmission (e.g., social coordination, language learning) <i> for </i> agents...
			    <br>
			    ...whereas agents in an epistemic proces may or may not use that transmission; both is in tension.

			  </section>


<!-- --------------------------------------------------------------- -->

			  <section>

			    <h2> Reason: Epistemic Processes </h2>
Phenomenon: "Overimitation" = transmission without infering causal rules
			    <br>
			    uncritical accepting testimony from others (remark RP: almost like "overfitting models) without causal inference
			    <br>
LLM/ Vision do not differentiate in output between epistemic uncertainty (lack of knowledge > more data) and aleatoric uncertainty (stochaisticity).
			    <br>
			   This could be one of the reasons that such visions "hallucinate" (remark RP: not that much any longer)
			  </section>


<!-- --------------------------------------------------------------- -->
			  <section>

			    <h2> Reason: Epistemic Processes </h2>
<div class="row">
    <img src="hal.jpg" alt="GPT_3" style="width:33%">
    <img src="hal_no.jpg" alt="GPT_4" style="width:33%">
</div>

			  </section>


<!-- --------------------------------------------------------------- -->


			  <section>

			    <h2> Reason: Epistemic Processes </h2>
Tension: transmission <> truth is close to Tension: imitation <> innovation in Cultural Evolution...
			   <br>
... which allows both continuation and adaptation; thus innovation (= extrapolation)
			   <br>
LLM/ Vision seem to work by generalisation, hence don't seem to innovate (= they interpolate)
			  </section>


<!-- --------------------------------------------------------------- -->

			  <section>

			    <h2> Reason: Epistemic Processes </h2>
... and, LLM/ Vision may not innovate, but just remember information from training data that lives now in the model weights.
			   <br>
Hence, it may help in cultural transmission, yet maybe not in innovation.
			  </section>


<!-- --------------------------------------------------------------- -->

			  
			  </section>


<!-- =========================================================================================================================  -->
		  
			  <section>
			  <section>

			    <h2> LLM and Vision as Imitation Engines </h2>
			   <br>
Imitation is a crucial cultural skill, which LLM master and facilitate.
			  </section>

<!-- --------------------------------------------------------------- -->

			  <section>

			    <h2> Ways of Imitation </h2>

Information codificaiton and compression: Spoken Language > Print > Internet > LLM/ Vision
			    <br>
			    This transmission technology helps in the continuation of culture
			    <br>
Variety of new and abstract information is created, based on existing cultural information
			    <br>
LLM are more abstract and meticulous than humans, hence will fortify cultural transmission.
			   <br>
Remark RP: reminds me about Johnson (2022) and Atari (2023); but then, it would also be a way of cultural colonialisation.

			  </section>


<!-- --------------------------------------------------------------- -->

<!-- --------------------------------------------------------------- -->

			  <section>

			    <h2> Ways of Imitation </h2>
LLM are as good and better as kids in that regard and seem to be driven by goal representation.
			    <br>
However, children can not only use social learning (remark RP: Bobo doll), but also decompose information...
			    <br>
...e.g., in agent, target, object, movement path. Hence, they are driven by causal structure.
			  </section>


<!-- --------------------------------------------------------------- -->



			  </section>
			  
<!-- =========================================================================================================================  -->
			  
			  <section>
			  <section>

			    <h2> Can LLM and Vision Innovate/ Discover new Tools? </h2>
			   <br>

			   Tool use is evidence for the tension process between transmission and truth-seeking
			   This chapter is the hidden meat and potatoes of the paper, however well hidden.
			   It is also highly relevant for hybrid systems.

			  </section>
<!-- --------------------------------------------------------------- -->

			  <section>

			    <h2> Innovation/ Use of New Tools </h2>
Ability to transfer information is crucial to AI; e.g., in behaviour cloning in robotics, but also in transfer-learning.
			   <br>
However, the exploration of novel tools is something that biological intelligence excels in; humans, children, but also animals like cows.
			  </section>


<!-- --------------------------------------------------------------- -->

<!-- --------------------------------------------------------------- -->

			  <section>

			    <h2> Innovation/ Use of New Tools </h2>
			    Information about an object is encoded by humans, and then applied in a novel, abstract way (teapot as circle) by new causal properties, functional analogies and affordances.
			   <br>

			  </section>


<!-- --------------------------------------------------------------- -->

			  <section>

			    <h2> Innovation/ Use of New Tools </h2>
Concrete experiment: present problem and objects that are a) superficially similar b) superficially dissimilar c) totally irrelevant
			    <br>
			    Humans and children were well able to perform this task.
			    <br>
Models rather chose the closest similarity, which often was a wrong choice.
			   <br>

			  </section>


<!-- --------------------------------------------------------------- -->



			  </section>

<!-- =========================================================================================================================  -->
			  
			  <section>
			  <section>

			    <h2> Can LLM Discover Novel Causal Relationships/ use them for Interventions? </h2>

			    Children naturally excel in creating causal relationships and deploying them.
			   <br>
However, LLM failed, whereas behavioural-based algorithms did quite well.
			  </section>
<!-- --------------------------------------------------------------- -->

			  <section>

			    <h2> Discovering causal structure, and deploy it </h2>
Even small children excel at it; using a combination of transmission and "scientific" exploration of the world.
			   <br>
This causal discovery of children stretches beyond "intuitive physics" to psychological and social relationships
			  </section>


<!-- --------------------------------------------------------------- -->

<!-- --------------------------------------------------------------- -->

			  <section>

			    <h2> Discovering causal structure, and deploy it </h2>
Virtual Blicket Detector: connection of objects. 
			    <br>
			    used also new artefacts and combinations to go beyond transmission.
			   <br>
children excelled, however LLM (ChatGPT, PaLM, LaMDA) not, however deep reinforcement learning algorithms and behavioural cloning algorithms did well (A2C, PPO2).
			  </section>


<!-- --------------------------------------------------------------- -->


			  </section>

<!-- =========================================================================================================================  -->
			  <section>
			  <section>

			    <h2> Challenges of Studying LLM and Vision/ Questions Left Unanswered </h2>

			    Causal problems, innovation, or sentience are unsolved problems.
			    <br>
			    Aforementioned ideas and projects give avenues for novel exploration.

			  </section>
<!-- --------------------------------------------------------------- -->

			  <section>

			    <h2> Challenges and Open Questions </h2>

			    Some models closer to truth seeking behaviours of children than others. Those that are, excel. But can that be generalised?
			    <br>
			    Children can use statistical pattern recognition, reinforcement from adults, and conceptual understanding in a context-aware manner.

			  </section>
<!-- --------------------------------------------------------------- -->

			  <section>

			    <h2> Challenges and Open Questions </h2>

			    A specific problem is leaking of problem information into training data. Another, how to model curiosity, activity, self-supervision, and intrinsic motivation.
			    <br>
			   RLHF is opaque, and can be a route of transmission learning (remark RP: or of ideological influence. See new EU regulations) 
			    <br>
			    Is scale everything, or is there something beyond?

			  </section>


<!-- --------------------------------------------------------------- -->
			  </section>


<!-- =========================================================================================================================  -->


			  <!-- <section> -->

			    <!-- <h2> Summary </h2> -->

			   <!-- <br> -->

			  <!-- </section> -->


<!-- =========================================================================================================================  -->


			  <section>

			    <h2> My humble opinion </h2>


<ul>
  <li> (+) Transfer of developmental psychology to AI research in a very clear manner </li>
  <li> (+) Great overview, good ideas, sound logic </li>
  <li> (-) Totally neglects everything <i>inside</i> LLM/Vision </li>
  <li> (-) Dangerous technical and quantiative half-knowledge</li>
  <li> (-) Some bold claims/ assumptions </li>
  <li> (-) They don't get that language is the whole world of LLM; in many ways, those may already be more intelligent than humans</li>
</ul>
			   
			  </section>


<!-- =========================================================================================================================  -->










			  
			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
			});
		</script>
	</body>
</html>
